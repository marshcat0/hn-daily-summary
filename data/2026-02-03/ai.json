{
  "topic_id": "ai",
  "topic_name": "AI & Machine Learning",
  "description": "Artificial intelligence, machine learning, and LLMs",
  "date": "2026-02-03",
  "crawled_at": "2026-02-03T16:47:14.956764",
  "article_count": 25,
  "articles": [
    {
      "id": "hn-46862170",
      "title": "xAI joins SpaceX",
      "url": "https://www.spacex.com/updates#xai-joins-spacex",
      "source": "Hacker News",
      "score": 672,
      "comments_count": 1492,
      "comments_url": "https://news.ycombinator.com/item?id=46862170",
      "published_at": "2026-02-03T05:51:22",
      "author": "g-mork",
      "text": null
    },
    {
      "id": "hn-46858577",
      "title": "Todd C. Miller â€“ Sudo maintainer for over 30 years",
      "url": "https://www.millert.dev/",
      "source": "Hacker News",
      "score": 414,
      "comments_count": 211,
      "comments_url": "https://news.ycombinator.com/item?id=46858577",
      "published_at": "2026-02-03T01:25:26",
      "author": "wodniok",
      "text": null
    },
    {
      "id": "reddit-1qpewj7",
      "title": "AMA With Kimi, The Open-source Frontier Lab Behind Kimi K2.5 Model",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1qpewj7/ama_with_kimi_the_opensource_frontier_lab_behind/",
      "source": "r/LocalLLaMA",
      "score": 273,
      "comments_count": 242,
      "comments_url": "https://www.reddit.com/r/LocalLLaMA/comments/1qpewj7/ama_with_kimi_the_opensource_frontier_lab_behind/",
      "published_at": "2026-01-28T23:46:40",
      "author": "nekofneko",
      "text": "HiÂ [r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/)\n\nToday we are havingÂ **Kimi**, the research lab behind theÂ **Kimi**Â **K2.5**. Weâ€™re excited to have them open up and answer your questions directly.\n\nOur participants today:\n\n* [u/ComfortableAsk4494](https://www.reddit.com/user/ComfortableAsk4494/)\n* [u/zxytim](https://www.reddit.com/user/zxytim/)\n* [u/ppwwyyxx](https://www.reddit.com/user/ppwwyyxx/)\n\n**The AMA will run from 8 AM â€“ 11 AM PST, with the Kimi team continuing to follow up on questions over the next 24 hours.**\n\nhttps://preview.redd.it/3yq8msvp24gg1.png?width=2000&format=png&auto=webp&s=98c89b5d86ee1197799532fead6a84da2223b389\n\n>  \nThanks everyone for joining our AMA. The live part has ended and the Kimi team will be following up with more answers sporadically over the next 24 hours."
    },
    {
      "id": "hn-46855447",
      "title": "Nano-vLLM: How a vLLM-style inference engine works",
      "url": "https://neutree.ai/blog/nano-vllm-part-1",
      "source": "Hacker News",
      "score": 244,
      "comments_count": 24,
      "comments_url": "https://news.ycombinator.com/item?id=46855447",
      "published_at": "2026-02-02T20:52:35",
      "author": "yz-yu",
      "text": null
    },
    {
      "id": "reddit-1qu7jqi",
      "title": "GLM releases OCR model",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1qu7jqi/glm_releases_ocr_model/",
      "source": "r/LocalLLaMA",
      "score": 213,
      "comments_count": 30,
      "comments_url": "https://www.reddit.com/r/LocalLLaMA/comments/1qu7jqi/glm_releases_ocr_model/",
      "published_at": "2026-02-03T05:01:12",
      "author": "Mr_Moonsilver",
      "text": "https://huggingface.co/zai-org/GLM-OCR\n\nEnjoy my friends, looks like a banger! GLM cooking hard! Seems like a 1.4B-ish model (0.9B vision, 0.5B language). Must be super fast."
    },
    {
      "id": "hn-46864120",
      "title": "Firefox Getting New Controls to Turn Off AI Features",
      "url": "https://www.macrumors.com/2026/02/02/firefox-ai-toggle/",
      "source": "Hacker News",
      "score": 159,
      "comments_count": 67,
      "comments_url": "https://news.ycombinator.com/item?id=46864120",
      "published_at": "2026-02-03T07:54:02",
      "author": "stalfosknight",
      "text": null
    },
    {
      "id": "hn-46854534",
      "title": "My fast zero-allocation webserver using OxCaml",
      "url": "https://anil.recoil.org/notes/oxcaml-httpz",
      "source": "Hacker News",
      "score": 141,
      "comments_count": 48,
      "comments_url": "https://news.ycombinator.com/item?id=46854534",
      "published_at": "2026-02-02T18:45:44",
      "author": "noelwelsh",
      "text": null
    },
    {
      "id": "hn-46843805",
      "title": "Archive.today is directing a DDoS attack against my blog?",
      "url": "https://gyrovague.com/2026/02/01/archive-today-is-directing-a-ddos-attack-against-my-blog/",
      "source": "Hacker News",
      "score": 135,
      "comments_count": 44,
      "comments_url": "https://news.ycombinator.com/item?id=46843805",
      "published_at": "2026-02-01T13:11:53",
      "author": "gyrovague-com",
      "text": null
    },
    {
      "id": "hn-46858873",
      "title": "Advancing AI Benchmarking with Game Arena",
      "url": "https://blog.google/innovation-and-ai/models-and-research/google-deepmind/kaggle-game-arena-updates/",
      "source": "Hacker News",
      "score": 124,
      "comments_count": 51,
      "comments_url": "https://news.ycombinator.com/item?id=46858873",
      "published_at": "2026-02-03T01:49:07",
      "author": "salkahfi",
      "text": null
    },
    {
      "id": "reddit-1mpk2va",
      "title": "Announcing LocalLlama discord server & bot!",
      "url": "https://www.reddit.com/gallery/1mpk2va",
      "source": "r/LocalLLaMA",
      "score": 116,
      "comments_count": 65,
      "comments_url": "https://www.reddit.com/r/LocalLLaMA/comments/1mpk2va/announcing_localllama_discord_server_bot/",
      "published_at": "2025-08-14T07:21:05",
      "author": "HOLUPREDICTIONS",
      "text": null
    },
    {
      "id": "hn-46864517",
      "title": "GitHub discusses giving maintainers control to disable PRs",
      "url": "https://github.com/orgs/community/discussions/185387",
      "source": "Hacker News",
      "score": 103,
      "comments_count": 29,
      "comments_url": "https://news.ycombinator.com/item?id=46864517",
      "published_at": "2026-02-03T08:30:02",
      "author": "aofeisheng",
      "text": null
    },
    {
      "id": "hn-46865275",
      "title": "Banning lead in gas worked. The proof is in our hair",
      "url": "https://attheu.utah.edu/health-medicine/banning-lead-in-gas-worked-the-proof-is-in-our-hair/",
      "source": "Hacker News",
      "score": 89,
      "comments_count": 13,
      "comments_url": "https://news.ycombinator.com/item?id=46865275",
      "published_at": "2026-02-03T09:52:21",
      "author": "geox",
      "text": null
    },
    {
      "id": "reddit-1qulipj",
      "title": "Found a wallet-drain prompt-injection payload on Moltbook (screenshots) â€” builders: treat feeds as untrusted",
      "url": "https://www.reddit.com/gallery/1qulipj",
      "source": "r/LocalLLaMA",
      "score": 83,
      "comments_count": 33,
      "comments_url": "https://www.reddit.com/r/LocalLLaMA/comments/1qulipj/found_a_walletdrain_promptinjection_payload_on/",
      "published_at": "2026-02-03T15:24:08",
      "author": "Impressive-Willow593",
      "text": null
    },
    {
      "id": "reddit-1quhtzi",
      "title": "I built Qwen3-TTS Studio â€“ Clone your voice and generate podcasts locally, no ElevenLabs needed",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1quhtzi/i_built_qwen3tts_studio_clone_your_voice_and/",
      "source": "r/LocalLLaMA",
      "score": 68,
      "comments_count": 21,
      "comments_url": "https://www.reddit.com/r/LocalLLaMA/comments/1quhtzi/i_built_qwen3tts_studio_clone_your_voice_and/",
      "published_at": "2026-02-03T12:06:59",
      "author": "BC_MARO",
      "text": "Hey everyone,\n\nI've been using Qwen3-TTS and found the existing demo a bit limited for what I wanted to do. So I built a proper interface with fine-grained control and a killer feature: \\*\\*automated podcast generation\\*\\*.\n\n\\*\\*What it does:\\*\\*\n\n* ğŸ™ï¸ Clone any voice with just a 3-second audio sample\n* ğŸšï¸ Fine-tune parameters (temperature, top-k, top-p) with quality presets\n* ğŸ“» Generate complete podcasts from just a topic â€“ AI writes the script, assigns voices, and synthesizes everything\n* ğŸŒ 10 languages supported (Korean, English, Chinese, Japanese, etc.\n\nhttps://preview.redd.it/xhwyhek3g7hg1.png?width=1512&format=png&auto=webp&s=5911188217c24b99904cc569275eb7ba62b46f98\n\nCurrently uses gpt5.2 for script generation, but the architecture is modular â€“ you can swap in any local LLM (Qwen, Llama, etc.) if you want fully local.\n\n\\*\\*The TTS runs entirely local\\*\\* on your machine (macOS MPS / Linux CUDA). No API calls for voice synthesis = unlimited generations, zero cost.\n\nBasically: ElevenLabs-style voice cloning + NotebookLM-style podcast generation, but local.\n\nGitHub: [https://github.com/bc-dunia/qwen3-TTS-studio](https://github.com/bc-dunia/qwen3-TTS-studio)\n\nHappy to answer any questions!"
    },
    {
      "id": "reddit-1qtgzbv",
      "title": "[D] MSR Cambridge vs Amazon Applied Science internship, thoughts?",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1qtgzbv/d_msr_cambridge_vs_amazon_applied_science/",
      "source": "r/MachineLearning",
      "score": 46,
      "comments_count": 36,
      "comments_url": "https://www.reddit.com/r/MachineLearning/comments/1qtgzbv/d_msr_cambridge_vs_amazon_applied_science/",
      "published_at": "2026-02-02T09:16:40",
      "author": "StretchTurbulent7525",
      "text": "Hi all,\n\nIâ€™m a PhD student in the US working on LLM-related research and trying to decide between two summer internship offers. \n\n**Option 1:** Microsoft Research, Cambridge (UK)\n\n* Working with a very well-known researcher\n* Strong alignment with my PhD research\n* Research-focused environment, likely publications\n* Downside: UK compensation is \\~half of the US offer\n\n**Option 2:** Amazon Applied Science, US\n\n* Applied science role in the US\n* Significantly higher pay\n* May not be a pure research project but if my proposed method is purely built from academic data/models, it can lead to a paper submission.  \n\nFor people whoâ€™ve done MSR / Amazon AS / similar internships:\n\n* How much does **US-based networking** during a PhD internship actually matter for post-PhD roles?\n* Is the **research fit + advisor name** from MSR Cambridge typically more valuable than a US industry internship when staying in the US long-term?\n* Any regrets choosing fit/research over compensation (or vice versa)?\n\n  \nMy longer-term plan is to continue working in the US after my PhD (industry research or applied research), but Iâ€™m also curious whether building a strong UK/EU research network via MSR Cambridge could be valuable in ways Iâ€™m underestimating."
    },
    {
      "id": "hn-46782692",
      "title": "Training a trillion parameter model to be funny",
      "url": "https://jokegen.sdan.io/blog",
      "source": "Hacker News",
      "score": 35,
      "comments_count": 28,
      "comments_url": "https://news.ycombinator.com/item?id=46782692",
      "published_at": "2026-01-28T00:58:05",
      "author": "sdan",
      "text": null
    },
    {
      "id": "reddit-1quehcc",
      "title": "[D] Where is modern geometry actually useful in machine learning? (data, architectures, optimization)",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1quehcc/d_where_is_modern_geometry_actually_useful_in/",
      "source": "r/MachineLearning",
      "score": 30,
      "comments_count": 14,
      "comments_url": "https://www.reddit.com/r/MachineLearning/comments/1quehcc/d_where_is_modern_geometry_actually_useful_in/",
      "published_at": "2026-02-03T09:36:24",
      "author": "ternausX",
      "text": "**From April 2025 to January 2026, I worked through** [**Frankelâ€™s \"The Geometry of Physics\".**](https://www.goodreads.com/book/show/294139.The_Geometry_of_Physics)\n\nThe goal wasnâ€™t to â€œrelearn physicsâ€, but to rebuild a modern geometric toolbox and see which mature ideas from geometry and topology might still be underused in machine learning.\n\nThe book develops a large amount of machineryâ€”manifolds, differential forms, connections and curvature, Lie groups and algebras, bundles, gauge theory, variational principles, topologyâ€”and shows how these arise naturally across classical mechanics, electromagnetism, relativity, and quantum theory.\n\nA pattern that kept reappearing was:\n\n**structure â†’ symmetry â†’ invariance â†’ dynamics â†’ observables**\n\nPhysics was forced into coordinate-free and global formulations because local, naive approaches stopped working. In ML, we often encounter similar issuesâ€”parameters with symmetries, non-Euclidean spaces, data living on manifolds, generalization effects that feel global rather than localâ€”but we usually address them heuristically rather than structurally.\n\nIâ€™m not claiming that abstract math automatically leads to better models. Most ideas donâ€™t survive contact with practice. But when some do, they often enable qualitatively different behavior rather than incremental improvements.\n\nIâ€™m now trying to move closer to ML-adjacent geometry: geometric deep learning beyond graphs, Riemannian optimization, symmetry and equivariance, topology-aware learning.\n\nIâ€™d be very interested in pointers to work (books, lecture notes, papers, or practical case studies) that sits between **modern geometry/topology and modern ML**, especially answers to questions like:\n\n* which geometric ideas have actually influenced model or optimizer design beyond toy settings?\n* where does Riemannian or manifold-aware optimization help in practice, and where is it mostly cosmetic?\n* which topological ideas seem fundamentally incompatible with SGD-style training?\n\nPointers and critical perspectives are very welcome."
    },
    {
      "id": "reddit-1qtr62c",
      "title": "[P] PerpetualBooster v1.1.2: GBM without hyperparameter tuning, now 2x faster with ONNX/XGBoost support",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1qtr62c/p_perpetualbooster_v112_gbm_without/",
      "source": "r/MachineLearning",
      "score": 28,
      "comments_count": 8,
      "comments_url": "https://www.reddit.com/r/MachineLearning/comments/1qtr62c/p_perpetualbooster_v112_gbm_without/",
      "published_at": "2026-02-02T18:09:42",
      "author": "mutlu_simsek",
      "text": "Hi all,\n\nWe just released v1.1.2 of PerpetualBooster. For those who haven't seen it, it's a gradient boosting machine (GBM) written in Rust that eliminates the need for hyperparameter optimization by using a generalization algorithm controlled by a single \"budget\" parameter.\n\nThis update focuses on performance, stability, and ecosystem integration.\n\nKey Technical Updates:\n- Performance: up to 2x faster training.\n- Ecosystem: Full R release, ONNX support, and native \"Save as XGBoost\" for interoperability.\n- Python Support: Added Python 3.14, dropped 3.9.\n- Data Handling: Zero-copy Polars support (no memory overhead).\n- API Stability: v1.0.0 is now the baseline, with guaranteed backward compatibility for all 1.x.x releases (compatible back to v0.10.0).\n\nBenchmarking against LightGBM + Optuna typically shows a 100x wall-time speedup to reach the same accuracy since it hits the result in a single run.\n\nGitHub: https://github.com/perpetual-ml/perpetual\n\nWould love to hear any feedback or answer questions about the algorithm!\n"
    },
    {
      "id": "reddit-1qu7voe",
      "title": "[D] Your pet peeves in ML research ?",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1qu7voe/d_your_pet_peeves_in_ml_research/",
      "source": "r/MachineLearning",
      "score": 26,
      "comments_count": 57,
      "comments_url": "https://www.reddit.com/r/MachineLearning/comments/1qu7voe/d_your_pet_peeves_in_ml_research/",
      "published_at": "2026-02-03T05:13:13",
      "author": "al3arabcoreleone",
      "text": "For researchers, what parts of academic machine learning environement irritates you the most ? what do you suggest to fix the problem ?"
    },
    {
      "id": "reddit-1qufx6b",
      "title": "[D] Optimal Transport for ML",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1qufx6b/d_optimal_transport_for_ml/",
      "source": "r/MachineLearning",
      "score": 15,
      "comments_count": 9,
      "comments_url": "https://www.reddit.com/r/MachineLearning/comments/1qufx6b/d_optimal_transport_for_ml/",
      "published_at": "2026-02-03T10:39:07",
      "author": "arjun_r_kaushik",
      "text": "Where should one start to learn Optimal Transport for ML? I am finding it hard to follow the math in the book â€œComputational Optimal Transportâ€. Any pointers to some simplified versions or even an application oriented resource would be great!\n\nThanks!"
    },
    {
      "id": "reddit-1qttn5c",
      "title": "[Project] TensorSeal: A tool to deploy TFLite models on Android without exposing the .tflite file",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1qttn5c/project_tensorseal_a_tool_to_deploy_tflite_models/",
      "source": "r/MachineLearning",
      "score": 14,
      "comments_count": 8,
      "comments_url": "https://www.reddit.com/r/MachineLearning/comments/1qttn5c/project_tensorseal_a_tool_to_deploy_tflite_models/",
      "published_at": "2026-02-02T20:24:33",
      "author": "orcnozyrt",
      "text": "*Note: I posted this on* r/androiddev *but thought the deployment side might interest this sub.*\n\nOne of the biggest pains in mobile ML deployment is that your trained model usually sits unencrypted in the APK. If you spent $50k fine-tuning a model, that's a liability.\n\nI open-sourced a tool called **TensorSeal** that handles the encryption/decryption pipeline for Android.\n\nIt ensures the model is only decrypted in memory (RAM) right before inference, keeping the disk footprint encrypted. It uses the TFLite C API to load directly from the buffer.\n\nHope it helps anyone deploying custom models to edge devices.\n\n**GitHub:**[https://github.com/NerdzHub/TensorSeal\\_Android](https://github.com/NerdzHub/TensorSeal_Android)"
    },
    {
      "id": "reddit-1qrrayn",
      "title": "[D] Monthly Who's Hiring and Who wants to be Hired?",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1qrrayn/d_monthly_whos_hiring_and_who_wants_to_be_hired/",
      "source": "r/MachineLearning",
      "score": 11,
      "comments_count": 4,
      "comments_url": "https://www.reddit.com/r/MachineLearning/comments/1qrrayn/d_monthly_whos_hiring_and_who_wants_to_be_hired/",
      "published_at": "2026-01-31T11:30:32",
      "author": "AutoModerator",
      "text": "**For Job Postings** please use this template\n\n>Hiring: \\[Location\\], Salary:\\[\\], \\[Remote | Relocation\\], \\[Full Time | Contract | Part Time\\]    and \\[Brief overview, what you're looking for\\]\n\n**For Those looking for jobs** please use this template\n\n>Want to be Hired: \\[Location\\], Salary Expectation:\\[\\], \\[Remote | Relocation\\], \\[Full Time | Contract | Part Time\\]  Resume: \\[Link to resume\\] and \\[Brief overview, what you're looking for\\]\n\n&#x200B;\n\nPlease remember that this community is geared towards those with experience."
    },
    {
      "id": "reddit-1qu28wx",
      "title": "[D] New interesting AI papers exploration service",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1qu28wx/d_new_interesting_ai_papers_exploration_service/",
      "source": "r/MachineLearning",
      "score": 8,
      "comments_count": 10,
      "comments_url": "https://www.reddit.com/r/MachineLearning/comments/1qu28wx/d_new_interesting_ai_papers_exploration_service/",
      "published_at": "2026-02-03T01:55:23",
      "author": "ArtisticHamster",
      "text": "A lot of time ago, I used arxiv sanity to see what's hot in AI papers. Which tool do you use to explore what's new and interesting in 2026?\n"
    },
    {
      "id": "reddit-1qu1tug",
      "title": "[D] Looking for advice regarding shortage of references for comparison in my research work",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1qu1tug/d_looking_for_advice_regarding_shortage_of/",
      "source": "r/MachineLearning",
      "score": 7,
      "comments_count": 8,
      "comments_url": "https://www.reddit.com/r/MachineLearning/comments/1qu1tug/d_looking_for_advice_regarding_shortage_of/",
      "published_at": "2026-02-03T01:40:57",
      "author": "Curious-Monitor497",
      "text": "I'm working in machine learning- application field. There are very few references which apply machine learning framework in my field of interest. So, even if I have comparison results of our framework with *one* baseline, I am unable to find more methods that solve the problem I am interested in.\n\nI see there is an in-depth comparision analysis provided in the machine learning conference papers. How to manage my analysis work with very few comparison results? I can perform additional experiments in even higher dimensions, but other than that, I'm unsure how to proceed from there.\n\nI would appreciate any advice and suggestions to move forward in such situation. Thank you in advance."
    },
    {
      "id": "reddit-1qtjnbc",
      "title": "[D] Self-Promotion Thread",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1qtjnbc/d_selfpromotion_thread/",
      "source": "r/MachineLearning",
      "score": 1,
      "comments_count": 2,
      "comments_url": "https://www.reddit.com/r/MachineLearning/comments/1qtjnbc/d_selfpromotion_thread/",
      "published_at": "2026-02-02T11:15:21",
      "author": "AutoModerator",
      "text": "Please post your personal projects, startups, product placements, collaboration needs, blogs etc.\n\nPlease mention the payment and pricing requirements for products and services.\n\nPlease do not post link shorteners, link aggregator websites , or auto-subscribe links.\n\n\\--\n\nAny abuse of trust will lead to bans.\n\nEncourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\n\\--\n\nMeta: This is an experiment. If the community doesnt like this, we will cancel it. This is to encourage those in the community to promote their work by not spamming the main threads."
    }
  ],
  "summary": "å¥½çš„ï¼Œä½œä¸ºä¸€åæŠ€æœ¯æ–°é—»åˆ†æå¸ˆï¼Œæˆ‘å·²å¯¹ä»Šæ—¥â€œAI & Machine Learningâ€ä¸»é¢˜ä¸‹çš„25ç¯‡çƒ­é—¨æ–‡ç« è¿›è¡Œäº†ç»¼åˆåˆ†æã€‚è¿™äº›å†…å®¹ä¸»è¦æ¥è‡ªHacker Newsã€Redditçš„r/LocalLLaMAå’Œr/MachineLearningç­‰ç¤¾åŒºï¼Œåæ˜ äº†å½“å‰ä¸šç•Œå’Œå­¦æœ¯ç•Œçš„çƒ­ç‚¹ã€‚\n\nä»¥ä¸‹æ˜¯æŒ‰å­ä¸»é¢˜æˆ–å…³é”®è¯åˆ†ç»„çš„æ€»ç»“æŠ¥å‘Šï¼š\n\n---\n\n### **ä¸€ã€ è¡Œä¸šåŠ¨æ€ä¸å…¬å¸æ–°é—»**\n\næ­¤ç±»åˆ«å…³æ³¨AIé¢†åŸŸçš„é‡è¦å•†ä¸šåˆä½œã€äº§å“æ›´æ–°å’Œè¡Œä¸šè¶‹åŠ¿ã€‚\n\n1.  **xAI joins SpaceX**\n    *   **è¯´æ˜**ï¼šè¿™æ˜¯ä»Šæ—¥æœ€çƒ­é—¨çš„æ–°é—»ï¼Œé©¬æ–¯å…‹æ——ä¸‹çš„xAIï¼ˆäººå·¥æ™ºèƒ½å…¬å¸ï¼‰æ­£å¼å¹¶å…¥SpaceXã€‚æ­¤ä¸¾é¢„ç¤ºç€AIä¸èˆªå¤©æŠ€æœ¯çš„æ·±åº¦ç»“åˆï¼Œå¯èƒ½æ¶‰åŠæ˜Ÿé“¾æ•°æ®åˆ©ç”¨ã€å¤ªç©ºè®¡ç®—æˆ–è‡ªä¸»ç³»ç»Ÿç­‰æ–¹å‘ï¼Œæˆ˜ç•¥æ„ä¹‰é‡å¤§ã€‚\n    *   **æ–‡ç« é“¾æ¥**ï¼šhttps://www.spacex.com/updates#xai-joins-spacex\n    *   **è®¨è®ºé“¾æ¥**ï¼šhttps://news.ycombinator.com/item?id=46862170\n\n6.  **Firefox Getting New Controls to Turn Off AI Features**\n    *   **è¯´æ˜**ï¼šFirefoxæµè§ˆå™¨è®¡åˆ’å¢åŠ ä¸€é”®å…³é—­æ‰€æœ‰AIåŠŸèƒ½çš„æ§åˆ¶é€‰é¡¹ã€‚è¿™åæ˜ äº†ç”¨æˆ·å¯¹éšç§å’Œè‡ªä¸»æ§åˆ¶æƒçš„å¼ºçƒˆéœ€æ±‚ï¼Œä¹Ÿæ˜¯ä¸»æµè½¯ä»¶åº”å¯¹AIé›†æˆæµªæ½®ï¼ˆå¦‚å†…ç½®åŠ©æ‰‹ã€å†…å®¹ç”Ÿæˆï¼‰çš„ç§¯æä¸¾æªã€‚\n    *   **æ–‡ç« é“¾æ¥**ï¼šhttps://www.macrumors.com/2026/02/02/firefox-ai-toggle/\n    *   **è®¨è®ºé“¾æ¥**ï¼šhttps://news.ycombinator.com/item?id=46864120\n\n11. **GitHub discusses giving maintainers control to disable PRs**\n    *   **è¯´æ˜**ï¼šGitHubæ­£åœ¨ç¤¾åŒºè®¨è®ºæ˜¯å¦å…è®¸ä»“åº“ç»´æŠ¤è€…ç¦ç”¨æ‹‰å–è¯·æ±‚ï¼ˆPRsï¼‰ã€‚è¿™ä¸»è¦é’ˆå¯¹AIè¾…åŠ©ç¼–ç¨‹å·¥å…·ï¼ˆå¦‚Copilotï¼‰ç”Ÿæˆçš„å¤§é‡ä½è´¨é‡æˆ–è‡ªåŠ¨åŒ–PRsï¼Œæ—¨åœ¨å‡è½»ç»´æŠ¤è€…è´Ÿæ‹…ï¼Œæ˜¯AIå·¥å…·æ™®åŠåå¯¹å¼€æºå·¥ä½œæµäº§ç”Ÿå†²å‡»çš„ç›´æ¥ä½“ç°ã€‚\n    *   **æ–‡ç« é“¾æ¥**ï¼šhttps://github.com/orgs/community/discussions/185387\n    *   **è®¨è®ºé“¾æ¥**ï¼šhttps://news.ycombinator.com/item?id=46864517\n\n### **äºŒã€ å¼€æºæ¨¡å‹ä¸ç¤¾åŒº**\n\nèšç„¦äºæœ€æ–°çš„å¼€æºAIæ¨¡å‹å‘å¸ƒã€ç¤¾åŒºæ´»åŠ¨åŠå·¥å…·ã€‚\n\n3.  **AMA With Kimi, The Open-source Frontier Lab Behind Kimi K2.5 Model**\n    *   **è¯´æ˜**ï¼šå¼€æºå‰æ²¿å®éªŒå®¤Kimiåœ¨r/LocalLLaMAç¤¾åŒºè¿›è¡Œâ€œé—®æˆ‘ä»»ä½•äº‹â€ï¼ˆAMAï¼‰æ´»åŠ¨ã€‚Kimi K2.5æ˜¯ä¸€ä¸ªå¤‡å—å…³æ³¨çš„å¼€æºå¤§æ¨¡å‹ï¼Œæ­¤æ¬¡æ´»åŠ¨ä¸ºå¼€å‘è€…æä¾›äº†ç›´æ¥ä¸ç ”å‘å›¢é˜Ÿäº¤æµæŠ€æœ¯ç»†èŠ‚å’Œæœªæ¥è·¯çº¿å›¾çš„æœºä¼šã€‚\n    *   **æ–‡ç« é“¾æ¥**ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1qpewj7/ama_with_kimi_the_opensource_frontier_lab_behind/\n    *   **è®¨è®ºé“¾æ¥**ï¼šåŒä¸Š\n\n5.  **GLM releases OCR model**\n    *   **è¯´æ˜**ï¼šæ™ºè°±AIï¼ˆGLMï¼‰å‘å¸ƒäº†ä¸€ä¸ªå¼€æºçš„OCRï¼ˆå…‰å­¦å­—ç¬¦è¯†åˆ«ï¼‰æ¨¡å‹ã€‚è¿™æ˜¯ä¸€ä¸ªè½»é‡çº§ï¼ˆçº¦14äº¿å‚æ•°ï¼‰çš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œä¸“æ³¨äºæ–‡æœ¬è¯†åˆ«ä»»åŠ¡ï¼Œä¸ºå¼€å‘è€…æä¾›äº†ä¸€ä¸ªå¯æœ¬åœ°éƒ¨ç½²ã€å¿«é€Ÿé«˜æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆã€‚\n    *   **æ–‡ç« é“¾æ¥**ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1qu7jqi/glm_releases_ocr_model/\n    *   **è®¨è®ºé“¾æ¥**ï¼šåŒä¸Š\n\n10. **Announcing LocalLlama discord server & bot!**\n    *   **è¯´æ˜**ï¼šr/LocalLLaMAå­è®ºå›å®£å¸ƒæ¨å‡ºå®˜æ–¹DiscordæœåŠ¡å™¨å’Œæœºå™¨äººã€‚è¿™æ ‡å¿—ç€è¿™ä¸ªä¸“æ³¨äºæœ¬åœ°è¿è¡Œå¤§æ¨¡å‹çš„ç¤¾åŒºæ­£åœ¨æ‰©å¤§å…¶å®æ—¶äº¤æµå’Œåä½œçš„é˜µåœ°ï¼Œæœ‰åˆ©äºçŸ¥è¯†åˆ†äº«å’Œé¡¹ç›®åˆä½œã€‚\n    *   **æ–‡ç« é“¾æ¥**ï¼šhttps://www.reddit.com/gallery/1mpk2va\n    *   **è®¨è®ºé“¾æ¥**ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1mpk2va/announcing_localllama_discord_server_bot/\n\n14. **I built Qwen3-TTS Studio â€“ Clone your voice and generate podcasts locally**\n    *   **è¯´æ˜**ï¼šä¸€ä½å¼€å‘è€…åŸºäºé€šä¹‰åƒé—®çš„Qwen3-TTSæ¨¡å‹ï¼Œæ„å»ºäº†ä¸€ä¸ªæœ¬åœ°è¯­éŸ³å…‹éš†å’Œæ’­å®¢ç”Ÿæˆå·¥å…·ã€‚å®ƒå…è®¸ç”¨æˆ·ä»…ç”¨3ç§’éŸ³é¢‘æ ·æœ¬å…‹éš†å£°éŸ³ï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆå®Œæ•´æ’­å®¢ï¼Œå±•ç¤ºäº†å¼€æºè¯­éŸ³æ¨¡å‹åœ¨åˆ›æ„å’Œç”Ÿäº§åŠ›æ–¹é¢çš„åº”ç”¨æ½œåŠ›ã€‚\n    *   **æ–‡ç« é“¾æ¥**ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1quhtzi/i_built_qwen3tts_studio_clone_your_voice_and/\n    *   **è®¨è®ºé“¾æ¥**ï¼šåŒä¸Š\n\n### **ä¸‰ã€ ç ”ç©¶ä¸æŠ€æœ¯æ·±åº¦æ¢è®¨**\n\næ¶µç›–æœºå™¨å­¦ä¹ ç ”ç©¶ã€ç®—æ³•ã€ç†è®ºåŠå‰æ²¿æŠ€æœ¯è§£æã€‚\n\n4.  **Nano-vLLM: How a vLLM-style inference engine works**\n    *   **è¯´æ˜**ï¼šä¸€ç¯‡æŠ€æœ¯åšå®¢ï¼Œè¯¦ç»†è§£æäº†å¦‚ä½•æ„å»ºä¸€ä¸ªç±»ä¼¼vLLMçš„é«˜æ€§èƒ½å¤§æ¨¡å‹æ¨ç†å¼•æ“ã€‚å¯¹äºå¸Œæœ›æ·±å…¥ç†è§£LLMæœåŠ¡åº•å±‚ä¼˜åŒ–ï¼ˆå¦‚PagedAttentionã€å†…å­˜ç®¡ç†ï¼‰çš„å·¥ç¨‹å¸ˆå’Œç ”ç©¶è€…æ¥è¯´ï¼Œæ˜¯æä½³çš„å­¦ä¹ ææ–™ã€‚\n    *   **æ–‡ç« é“¾æ¥**ï¼šhttps://neutree.ai/blog/nano-vllm-part-1\n    *   **è®¨è®ºé“¾æ¥**ï¼šhttps://news.ycombinator.com/item?id=46855447\n\n9.  **Advancing AI Benchmarking with Game Arena**\n    *   **è¯´æ˜**ï¼šGoogle DeepMindå®£å¸ƒæ›´æ–°Kaggleä¸Šçš„â€œæ¸¸æˆç«æŠ€åœºâ€åŸºå‡†æµ‹è¯•ã€‚é€šè¿‡è®©AIæ™ºèƒ½ä½“åœ¨ã€Šæˆ‘çš„ä¸–ç•Œã€‹ç­‰å¤æ‚æ¸¸æˆç¯å¢ƒä¸­ç«äº‰ï¼Œæ—¨åœ¨æ¨åŠ¨èƒ½è§£å†³å¼€æ”¾å¼ã€å¤šæ­¥éª¤ä»»åŠ¡çš„AIç³»ç»Ÿçš„å‘å±•ï¼Œæ˜¯è¯„ä¼°AIé€šç”¨èƒ½åŠ›çš„æ–°æ–¹å‘ã€‚\n    *   **æ–‡ç« é“¾æ¥**ï¼šhttps://blog.google/innovation-and-ai/models-and-research/google-deepmind/kaggle-game-arena-updates/\n    *   **è®¨è®ºé“¾æ¥**ï¼šhttps://news.ycombinator.com/item?id=46858873\n\n16. **Training a trillion parameter model to be funny**\n    *   **è¯´æ˜**ï¼šä¸€ä¸ªæœ‰è¶£çš„å®éªŒé¡¹ç›®ï¼Œå°è¯•è®­ç»ƒä¸€ä¸ªä¸‡äº¿å‚æ•°çº§åˆ«çš„æ¨¡å‹æ¥ç”Ÿæˆç¬‘è¯ã€‚è¿™è§¦åŠäº†AIåœ¨åˆ›é€ æ€§ã€å¹½é»˜æ„Ÿè¿™ç§é«˜åº¦ä¸»è§‚å’Œäººç±»åŒ–ä»»åŠ¡ä¸Šçš„æŒ‘æˆ˜ï¼Œè™½ç„¶è§„æ¨¡å¤¸å¼ ï¼Œä½†å¼•å‘äº†å…³äºæ¨¡å‹è§„æ¨¡ä¸â€œç†è§£â€èƒ½åŠ›çš„è®¨è®ºã€‚\n    *   **æ–‡ç« é“¾æ¥**ï¼šhttps://jokegen.sdan.io/blog\n    *   **è®¨è®ºé“¾æ¥**ï¼šhttps://news.ycombinator.com/item?id=46782692\n\n17. **[D] Where is modern geometry actually useful in machine learning?**\n    *   **è¯´æ˜**ï¼šr/MachineLearningä¸Šçš„è®¨è®ºå¸–ï¼Œæ¢è®¨ç°ä»£å‡ ä½•ï¼ˆå¦‚æµå½¢ã€å¾®åˆ†å½¢å¼ï¼‰åœ¨æœºå™¨å­¦ä¹ ï¼ˆæ•°æ®ã€æ¶æ„ã€ä¼˜åŒ–ï¼‰ä¸­çš„å®é™…åº”ç”¨ã€‚è¿™æ˜¯ä¸€ä¸ªè¿æ¥åŸºç¡€æ•°å­¦ä¸å‰æ²¿AIçš„æ·±åº¦è¯é¢˜ï¼Œå¸å¼•äº†ç ”ç©¶è€…åˆ†äº«åœ¨ç”Ÿæˆæ¨¡å‹ã€å›¾ç¥ç»ç½‘ç»œç­‰é¢†åŸŸçš„å‡ ä½•è§‚ç‚¹ã€‚\n    *   **æ–‡ç« é“¾æ¥**ï¼šhttps://www.reddit.com/r/MachineLearning/comments/1quehcc/d_where_is_modern_geometry_actually_useful_in/\n    *   **è®¨è®ºé“¾æ¥**ï¼šåŒä¸Š\n\n20. **[D] Optimal Transport for ML**\n    *   **è¯´æ˜**ï¼šå¦ä¸€ä¸ªç†è®ºè”ç³»å®é™…çš„è®¨è®ºï¼Œå¯»æ±‚å­¦ä¹ â€œæœ€ä¼˜ä¼ è¾“â€ç†è®ºåŠå…¶åœ¨æœºå™¨å­¦ä¹ ä¸­åº”ç”¨çš„èµ„æºã€‚æœ€ä¼˜ä¼ è¾“åœ¨ç”Ÿæˆæ¨¡å‹ã€é¢†åŸŸè‡ªé€‚åº”å’Œè¡¨ç¤ºå­¦ä¹ ä¸­è¶Šæ¥è¶Šé‡è¦ï¼Œæ­¤å¸–åæ˜ äº†ç¤¾åŒºå¯¹æŒæ¡è¿™ä¸€æ•°å­¦å·¥å…·çš„éœ€æ±‚ã€‚\n    *   **æ–‡ç« é“¾æ¥**ï¼šhttps://www.reddit.com/r/MachineLearning/comments/1qufx6b/d_optimal_transport_for_ml/\n    *   **è®¨è®ºé“¾æ¥**ï¼šåŒä¸Š\n\n### **å››ã€ å·¥ç¨‹å®è·µä¸å·¥å…·**\n\nå…³æ³¨å…·ä½“çš„æœºå™¨å­¦ä¹ å·¥ç¨‹ã€éƒ¨ç½²ã€ä¼˜åŒ–å·¥å…·å’Œå®è·µç»éªŒã€‚\n\n13. **Found a wallet-drain prompt-injection payload on Moltbook**\n    *   **è¯´æ˜**ï¼šä¸€åå¼€å‘è€…åœ¨Moltbookå¹³å°ä¸Šå‘ç°äº†ä¸€ä¸ªæ—¨åœ¨ç›—å–åŠ å¯†è´§å¸é’±åŒ…çš„æç¤ºè¯æ³¨å…¥æ”»å‡»è½½è·ã€‚è¿™æ˜¯ä¸€ä¸ªé‡è¦çš„å®‰å…¨è­¦ç¤ºï¼Œæé†’æ‰€æœ‰åŸºäºLLMæ„å»ºåº”ç”¨çš„å¼€å‘è€…ï¼Œå¿…é¡»å°†å¤–éƒ¨è¾“å…¥ï¼ˆå¦‚RSSæºï¼‰è§†ä¸ºä¸å¯ä¿¡æ•°æ®ï¼Œå¹¶åšå¥½æ²™ç®±éš”ç¦»ã€‚\n    *   **æ–‡ç« é“¾æ¥**ï¼šhttps://www.reddit.com/gallery/1qulipj\n    *   **è®¨è®ºé“¾æ¥**ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1qulipj/found_a_walletdrain_promptinjection_payload_on/\n\n18. **[P] PerpetualBooster v1.1.2: GBM without hyperparameter tuning**\n    *   **è¯´æ˜**ï¼šä¸€ä¸ªç”¨Rustç¼–å†™çš„æ¢¯åº¦æå‡æœºï¼ˆGBMï¼‰åº“æ›´æ–°ï¼Œä¸»æ‰“æ— éœ€è¶…å‚æ•°è°ƒä¼˜ï¼Œé€šè¿‡å•ä¸€â€œé¢„ç®—â€å‚æ•°æ§åˆ¶ï¼Œæœ¬æ¬¡æ›´æ–°æ€§èƒ½æå‡2å€å¹¶æ”¯æŒONNX/XGBoostã€‚ä¸ºéœ€è¦å¿«é€Ÿéƒ¨ç½²ã€å¯è§£é‡Šæ€§å¼ºçš„è¡¨æ ¼æ•°æ®å»ºæ¨¡æä¾›äº†æ–°é€‰æ‹©ã€‚\n    *   **æ–‡ç« é“¾æ¥**ï¼šhttps://www.reddit.com/r/MachineLearning/comments/1qtr62c/p_perpetualbooster_v112_gbm_without/\n    *   **è®¨è®ºé“¾æ¥**ï¼šåŒä¸Š\n\n21. **[Project] TensorSeal: A tool to deploy TFLite models on Android without exposing the .tflite file**\n    *   **è¯´æ˜**ï¼šä¸€ä¸ªå¼€æºå·¥å…·ï¼Œæ—¨åœ¨è§£å†³ç§»åŠ¨ç«¯MLæ¨¡å‹éƒ¨ç½²çš„å®‰å…¨é—®é¢˜ã€‚å®ƒé€šè¿‡å¯¹TFLiteæ¨¡å‹è¿›è¡ŒåŠ å¯†ï¼Œç¡®ä¿å…¶åœ¨APKä¸­ä¸å¯è§ï¼Œä»…åœ¨å†…å­˜ä¸­è§£å¯†ç”¨äºæ¨ç†ï¼Œä¿æŠ¤äº†æ˜‚è´µè®­ç»ƒæ‰€å¾—æ¨¡å‹çš„çŸ¥è¯†äº§æƒã€‚\n    *   **æ–‡ç« é“¾æ¥**ï¼šhttps://www.reddit.com/r/MachineLearning/comments/1qttn5c/project_tensorseal_a_tool_to_deploy_tflite_models/\n    *   **è®¨è®ºé“¾æ¥**ï¼šåŒä¸Š\n\n### **äº”ã€ å­¦æœ¯ä¸èŒä¸šç¤¾åŒº**\n\nåæ˜ æœºå™¨å­¦ä¹ å­¦æœ¯ç•Œå’Œå°±ä¸šå¸‚åœºçš„è®¨è®ºã€å»ºè®®ä¸èµ„æºã€‚\n\n15. **[D] MSR Cambridge vs Amazon Applied Science internship, thoughts?**\n    *   **è¯´æ˜**ï¼šä¸€ååšå£«ç”Ÿåœ¨å¾®è½¯ç ”ç©¶é™¢ï¼ˆè‹±å›½ï¼‰å’Œäºšé©¬é€Šåº”ç”¨ç§‘å­¦å®¶ï¼ˆç¾å›½ï¼‰çš„å®ä¹ æœºä¼šä¹‹é—´å¯»æ±‚å»ºè®®ã€‚å¸–å­å¼•å‘äº†å…³äºç ”ç©¶å¯¼å‘vs.åº”ç”¨å¯¼å‘ã€èŒä¸šå‘å±•ã€è–ªé…¬ä¸åœ°ç†ä½ç½®æƒè¡¡çš„å¹¿æ³›è®¨è®ºï¼Œéå¸¸è´´è¿‘å­¦ç”Ÿå’Œåˆå…¥è¡Œè€…çš„ç°å®è€ƒé‡ã€‚\n    *   **æ–‡ç« é“¾æ¥**ï¼šhttps://www.reddit.com/r/MachineLearning/comments/1qtgzbv/d_msr_cambridge_vs_amazon_applied_science/\n    *   **è®¨è®ºé“¾æ¥**ï¼šåŒä¸Š\n\n19. **[D] Your pet peeves in ML research ?**\n    *   **è¯´æ˜**ï¼šå¾é›†æœºå™¨å­¦ä¹ ç ”ç©¶é¢†åŸŸä¸­æœ€ä»¤äººçƒ¦æ¼çš„é—®é¢˜ã€‚è¿™ç±»å…ƒè®¨è®ºæœ‰åŠ©äºæ­ç¤ºå­¦æœ¯ç•Œåœ¨è®ºæ–‡è¯„å®¡ã€å¤ç°æ€§ã€ç‚’ä½œé£æ°”ç­‰æ–¹é¢å­˜åœ¨çš„ç³»ç»Ÿæ€§ç—›ç‚¹ï¼Œä¿ƒè¿›ç¤¾åŒºåæ€ã€‚\n    *   **æ–‡ç« é“¾æ¥**ï¼šhttps://www.reddit.com/r/MachineLearning/comments/1qu7voe/d_your_pet_peeves_in_ml_research/\n    *   **è®¨è®ºé“¾æ¥**ï¼šåŒä¸Š\n\n22. **[D] Monthly Whoâ€˜s Hiring and Who wants to be Hired?**\n    *   **è¯´æ˜**ï¼šr/MachineLearningç¤¾åŒºçš„æœˆåº¦æ‹›è˜ä¸æ±‚èŒä¸“å¸–ã€‚æ˜¯è§‚å¯ŸAI/MLå°±ä¸šå¸‚åœºçƒ­ç‚¹æ–¹å‘å’Œè–ªèµ„æ°´å¹³çš„ä¸€ä¸ªçª—å£ã€‚\n    *   **æ–‡ç« é“¾æ¥**ï¼šhttps://www.reddit.com/r/MachineLearning/comments/1qrrayn/d_monthly_whos_hiring_and_who_wants_to_be_hired/\n    *   **è®¨è®ºé“¾æ¥**ï¼šåŒä¸Š\n\n23, 24, 25. **ç³»åˆ—è®¨è®ºå¸–**\n    *   åŒ…æ‹¬å¯»æ‰¾AIè®ºæ–‡æ¢ç´¢å·¥å…·ã€ç ”ç©¶å·¥ä½œä¸­ç¼ºä¹å¯¹æ¯”åŸºå‡†çš„åº”å¯¹å»ºè®®ï¼Œä»¥åŠç¤¾åŒºè‡ªæˆ‘æ¨å¹¿ä¸“å¸–ã€‚è¿™äº›æ˜¯å­¦æœ¯ç ”ç©¶æ—¥å¸¸ä¸­å¸¸è§çš„å®ç”¨è¯é¢˜å’Œç¤¾åŒºäº’åŠ¨å½¢å¼ã€‚\n    *   **é“¾æ¥**ï¼šè§åŸæ–‡åˆ—è¡¨23, 24, 25ã€‚\n\n### **å…­ã€ å…¶ä»–æŠ€æœ¯ç›¸å…³**\n\nä¸AIä¸»é¢˜é—´æ¥ç›¸å…³æˆ–åŒæœŸå¼•èµ·æŠ€æœ¯ç¤¾åŒºå…³æ³¨çš„å†…å®¹ã€‚\n\n2, 7, 8, 12. **å…¶ä»–çƒ­é—¨æŠ€æœ¯æ–‡ç« **\n    *   åŒ…æ‹¬èµ„æ·±Sudoç»´æŠ¤è€…çš„æ•…äº‹ã€ç”¨OxCamlç¼–å†™é«˜æ€§èƒ½WebæœåŠ¡å™¨çš„ç»éªŒã€å…³äºArchive.todayæœåŠ¡çš„äº‰è®®ï¼Œä»¥åŠå…³äºå«é“…æ±½æ²¹ç¦ä»¤æ•ˆæœçš„ç ”ç©¶ã€‚è¿™äº›æ–‡ç« è™½ç„¶ä¸ç›´æ¥å±äºAI/MLæ ¸å¿ƒèŒƒç•´ï¼Œä½†å› åœ¨Hacker Newsç­‰é€šç”¨æŠ€æœ¯ç¤¾åŒºè·å¾—é«˜å…³æ³¨ï¼Œä¹Ÿåæ˜ äº†æŠ€æœ¯å—ä¼—çš„å¹¿æ³›å…´è¶£ç‚¹ã€‚\n    *   **é“¾æ¥**ï¼šè§åŸæ–‡åˆ—è¡¨2, 7, 8, 12ã€‚\n\n---\n\n### **ä»Šæ—¥æœ€å€¼å¾—é˜…è¯»æ–‡ç« æ¨è**\n\nåŸºäºæ–°é—»é‡è¦æ€§ã€æŠ€æœ¯æ·±åº¦å’Œå®ç”¨ä»·å€¼ï¼Œæˆ‘æ¨èä»¥ä¸‹5ç¯‡æ–‡ç« ï¼š\n\n1.  **xAI joins SpaceX**\n    *   **ç†ç”±**ï¼šä»Šæ—¥ç»å¯¹å¤´æ¡ï¼Œæ ‡å¿—ç€AIä¸å‰æ²¿èˆªå¤©ç§‘æŠ€çš„èåˆè¿›å…¥æ–°é˜¶æ®µï¼Œå¯èƒ½é‡å¡‘å¤šä¸ªè¡Œä¸šã€‚æ— è®ºæ˜¯å¯¹è¡Œä¸šè¶‹åŠ¿ã€æŠ•èµ„æ–¹å‘è¿˜æ˜¯æŠ€æœ¯æœªæ¥æ„Ÿå…´è¶£ï¼Œéƒ½ä¸åº”é”™è¿‡ã€‚\n    *   **é“¾æ¥**ï¼šhttps://www.spacex.com/updates#xai-joins-spacex åŠè®¨è®ºï¼šhttps://news.ycombinator.com/item?id=46862170\n\n2.  **Nano-vLLM: How a vLLM-style inference engine works**\n    *   **ç†ç”±**ï¼šå¯¹äºä»äº‹å¤§æ¨¡å‹éƒ¨ç½²å’Œä¼˜åŒ–çš„å·¥ç¨‹å¸ˆè€Œè¨€ï¼Œè¿™æ˜¯ä¸€ç¯‡ä¸å¯å¤šå¾—çš„æ·±åº¦æŠ€æœ¯è§£æã€‚å®ƒå‰¥å¼€äº†é«˜æ€§èƒ½æ¨ç†å¼•æ“çš„ç¥ç§˜é¢çº±ï¼Œæœ‰åŠ©äºè¯»è€…æ„å»ºè‡ªå·±çš„çŸ¥è¯†ä½“ç³»ã€‚\n    *   **é“¾æ¥**ï¼šhttps://neutree.ai/blog/nano-vllm-part-1\n\n3.  **AMA With Kimi, The Open-source Frontier Lab Behind Kimi K2.5 Model**\n    *   **ç†ç”±**ï¼šç›´æ¥ä¸çƒ­é—¨å¼€æºæ¨¡å‹å›¢é˜Ÿå¯¹è¯çš„æœºä¼šã€‚å¯¹äºå…³æ³¨å¼€æºæ¨¡å‹å‘å±•ã€æŠ€æœ¯é€‰å‹æˆ–æœ‰å…·ä½“ä½¿ç”¨é—®é¢˜çš„å¼€å‘è€…ï¼Œå¯ä»¥ä»ä¸­è·å¾—ç¬¬ä¸€æ‰‹ä¿¡æ¯å’Œæ´è§ã€‚\n    *   **é“¾æ¥**ï¼šhttps://www.reddit.com/r/LocalLLaMA/comments/1qpewj7/ama_with_kimi_the_opensource_frontier_lab_behind/\n\n4.  **Found a wallet-drain prompt-injection payload on Moltbook**\n    *   **ç†ç”±**ï¼šä¸€ä¸ªç”ŸåŠ¨ä¸”ä¸¥å³»çš„AIå®‰å…¨æ¡ˆä¾‹ã€‚æ‰€æœ‰æ­£åœ¨æˆ–å°†è¦ç”¨LLMæ„å»ºç”Ÿäº§çº§åº”ç”¨çš„å¼€å‘è€…ã€äº§å“ç»ç†éƒ½å¿…é¡»äº†è§£è¿™ç±»é£é™©ï¼Œå¹¶å­¦ä¹ å¦‚ä½•é˜²å¾¡æç¤ºè¯æ³¨å…¥æ”»å‡»ã€‚\n    *   **é“¾æ¥**ï¼šhttps://www.reddit.com/gallery/1qulipj\n\n5.  **[D] MSR Cambridge vs Amazon Applied Science internship, thoughts?**\n    *   **ç†ç”±**ï¼šå¯¹äºAI/MLé¢†åŸŸçš„å­¦ç”Ÿå’Œæ—©æœŸä»ä¸šè€…æå…·å‚è€ƒä»·å€¼ã€‚å…¶ä¸­çš„è®¨è®ºçœŸå®åæ˜ äº†å­¦æœ¯ç•Œä¸å·¥ä¸šç•Œçš„ä¸åŒè·¯å¾„ã€æƒè¡¡ä¸æœºé‡ï¼Œæ˜¯ä¸€å ‚ç”ŸåŠ¨çš„èŒä¸šè§„åˆ’è¯¾ã€‚\n    *   **é“¾æ¥**ï¼šhttps://www.reddit.com/r/MachineLearning/comments/1qtgzbv/d_msr_cambridge_vs_amazon_applied_science/\n\nå¸Œæœ›è¿™ä»½åˆ†ææ€»ç»“å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ã€‚",
  "summary_language": "zh"
}